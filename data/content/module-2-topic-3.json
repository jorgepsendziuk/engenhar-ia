{
  "id": "module-2-topic-3",
  "title": "Engenharia de prompts avançada",
  "content": "## Introdução\n\nNo [Módulo 1, Tópico 6](/topic/module-1-topic-6), exploramos os fundamentos de prompt engineering: como escrever prompts eficazes, estruturar instruções e obter boas respostas dos modelos. Agora, vamos aprofundar essas técnicas e explorar estratégias avançadas que permitem construir sistemas mais robustos, eficientes e confiáveis.\n\nEste tópico cobre três áreas críticas de prompt engineering avançado:\n\n1. **Prompt Chaining**: Encadear múltiplos prompts para resolver tarefas complexas\n2. **Prompt Templates**: Padronizar e reutilizar prompts em diferentes contextos\n3. **Redução de Alucinações**: Estratégias para melhorar a precisão e confiabilidade\n\nEssas técnicas são essenciais para desenvolvedores que constroem aplicações de IA em produção, onde consistência, confiabilidade e eficiência são fundamentais.\n\n## Revisão de Conceitos Básicos\n\nAntes de avançarmos, vamos revisar rapidamente os conceitos fundamentais de prompt engineering:\n\n### Estrutura de um Prompt Eficaz\n\nUm prompt bem estruturado geralmente contém:\n\n- **Contexto**: Informações de fundo necessárias\n- **Instrução**: O que você quer que o modelo faça\n- **Exemplos**: Casos de uso ou exemplos (few-shot learning)\n- **Formato**: Como você quer a resposta formatada\n- **Restrições**: Limitações ou regras a seguir\n\n### Princípios Fundamentais\n\n- **Clareza**: Seja específico e direto\n- **Contexto**: Forneça informações suficientes\n- **Estrutura**: Organize o prompt de forma lógica\n- **Iteração**: Refine prompts baseado em resultados\n\n## Prompt Chaining: Encadeando Prompts para Tarefas Complexas\n\n### O que é Prompt Chaining?\n\nPrompt chaining é uma técnica onde você divide uma tarefa complexa em múltiplas etapas menores, cada uma com seu próprio prompt. A saída de um prompt se torna a entrada do próximo, criando um pipeline de processamento.\n\n### Por que Usar Prompt Chaining?\n\n1. **Complexidade Gerenciável**: Tarefas complexas são mais fáceis de resolver quando divididas\n2. **Melhor Qualidade**: Cada etapa pode ser otimizada individualmente\n3. **Debugging**: Mais fácil identificar onde problemas ocorrem\n4. **Reutilização**: Etapas individuais podem ser reutilizadas em outros contextos\n5. **Controle**: Mais controle sobre cada etapa do processo\n\n### Exemplo Prático: Análise de Documento Complexo\n\nVamos criar um sistema que analisa um documento técnico e gera um resumo executivo:\n\n```javascript\n// Exemplo de Prompt Chaining\nconst { OpenAI } = require('openai');\nconst openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });\n\nasync function analyzeDocument(document) {\n  // Etapa 1: Extrair informações-chave\n  const keyPoints = await openai.chat.completions.create({\n    model: \"gpt-4\",\n    messages: [\n      {\n        role: \"system\",\n        content: \"Você é um especialista em análise de documentos. Extraia os pontos-chave principais.\"\n      },\n      {\n        role: \"user\",\n        content: `Analise este documento e extraia os 5 pontos-chave principais:\\n\\n${document}`\n      }\n    ],\n    temperature: 0.3\n  });\n  \n  const extractedPoints = keyPoints.choices[0].message.content;\n  \n  // Etapa 2: Identificar implicações\n  const implications = await openai.chat.completions.create({\n    model: \"gpt-4\",\n    messages: [\n      {\n        role: \"system\",\n        content: \"Você é um analista estratégico. Identifique implicações e consequências.\"\n      },\n      {\n        role: \"user\",\n        content: `Com base nestes pontos-chave, identifique as 3 principais implicações:\\n\\n${extractedPoints}`\n      }\n    ],\n    temperature: 0.5\n  });\n  \n  const identifiedImplications = implications.choices[0].message.content;\n  \n  // Etapa 3: Gerar resumo executivo\n  const summary = await openai.chat.completions.create({\n    model: \"gpt-4\",\n    messages: [\n      {\n        role: \"system\",\n        content: \"Você é um redator executivo. Crie resumos claros e concisos.\"\n      },\n      {\n        role: \"user\",\n        content: `Crie um resumo executivo de 3 parágrafos com base em:\\n\\nPontos-chave:\\n${extractedPoints}\\n\\nImplicações:\\n${identifiedImplications}`\n      }\n    ],\n    temperature: 0.7\n  });\n  \n  return {\n    keyPoints: extractedPoints,\n    implications: identifiedImplications,\n    executiveSummary: summary.choices[0].message.content\n  };\n}\n```\n\n### Padrões de Prompt Chaining\n\n#### 1. Pipeline Sequencial\n\nCada etapa depende da anterior:\n\n```javascript\nasync function sequentialChain(input) {\n  const step1 = await processStep1(input);\n  const step2 = await processStep2(step1);\n  const step3 = await processStep3(step2);\n  return step3;\n}\n```\n\n#### 2. Pipeline Paralelo\n\nMúltiplas etapas processam em paralelo e depois combinam:\n\n```javascript\nasync function parallelChain(input) {\n  const [result1, result2, result3] = await Promise.all([\n    processStep1(input),\n    processStep2(input),\n    processStep3(input)\n  ]);\n  \n  return combineResults(result1, result2, result3);\n}\n```\n\n#### 3. Pipeline Condicional\n\nO fluxo muda baseado em condições:\n\n```javascript\nasync function conditionalChain(input) {\n  const analysis = await analyzeInput(input);\n  \n  if (analysis.type === 'A') {\n    return await processTypeA(analysis);\n  } else if (analysis.type === 'B') {\n    return await processTypeB(analysis);\n  } else {\n    return await processDefault(analysis);\n  }\n}\n```\n\n#### 4. Pipeline com Validação\n\nCada etapa valida antes de prosseguir:\n\n```javascript\nasync function validatedChain(input) {\n  const step1 = await processStep1(input);\n  \n  if (!validateStep1(step1)) {\n    throw new Error('Validação falhou na etapa 1');\n  }\n  \n  const step2 = await processStep2(step1);\n  \n  if (!validateStep2(step2)) {\n    // Retry ou fallback\n    return await fallbackProcess(step1);\n  }\n  \n  return step2;\n}\n```\n\n### Boas Práticas de Prompt Chaining\n\n1. **Defina Objetivos Claros**: Cada etapa deve ter um objetivo específico e mensurável\n2. **Mantenha Contexto**: Passe informações relevantes entre etapas\n3. **Trate Erros**: Implemente tratamento de erros robusto em cada etapa\n4. **Otimize Individualmente**: Otimize cada prompt separadamente\n5. **Monitore Performance**: Acompanhe o desempenho de cada etapa\n6. **Documente o Fluxo**: Documente claramente o fluxo de dados\n\n## Prompt Templates: Padronização e Reutilização\n\n### O que são Prompt Templates?\n\nPrompt templates são estruturas reutilizáveis de prompts que permitem padronizar fluxos e facilitar a manutenção. Eles usam placeholders que são preenchidos com valores específicos em tempo de execução.\n\n### Benefícios dos Templates\n\n1. **Consistência**: Garante que prompts similares sigam o mesmo padrão\n2. **Manutenibilidade**: Mudanças em um template afetam todos os usos\n3. **Reutilização**: Templates podem ser usados em múltiplos contextos\n4. **Testabilidade**: Mais fácil testar e validar\n5. **Colaboração**: Facilita trabalho em equipe\n\n### Exemplo Básico de Template\n\n```javascript\n// Template simples\nconst analysisTemplate = `Você é um {role} especializado em {domain}.\n\nAnalise o seguinte {contentType}:\n\n{content}\n\nForneça uma análise focada em:\n- {focus1}\n- {focus2}\n- {focus3}\n\nFormato da resposta: {format}`;\n\nfunction fillTemplate(template, variables) {\n  let result = template;\n  for (const [key, value] of Object.entries(variables)) {\n    result = result.replace(new RegExp(`{${key}}`, 'g'), value);\n  }\n  return result;\n}\n\n// Uso\nconst prompt = fillTemplate(analysisTemplate, {\n  role: 'analista técnico',\n  domain: 'desenvolvimento de software',\n  contentType: 'código',\n  content: 'function example() { ... }',\n  focus1: 'qualidade do código',\n  focus2: 'possíveis bugs',\n  focus3: 'sugestões de melhoria',\n  format: 'lista com bullet points'\n});\n```\n\n### Sistema de Templates Avançado\n\nVamos criar um sistema mais robusto de templates:\n\n```javascript\nclass PromptTemplate {\n  constructor(template, variables = {}) {\n    this.template = template;\n    this.variables = variables;\n    this.requiredVars = this.extractVariables(template);\n  }\n  \n  extractVariables(template) {\n    const regex = /{([^}]+)}/g;\n    const matches = [...template.matchAll(regex)];\n    return matches.map(m => m[1]);\n  }\n  \n  setVariable(name, value) {\n    this.variables[name] = value;\n    return this;\n  }\n  \n  setVariables(vars) {\n    this.variables = { ...this.variables, ...vars };\n    return this;\n  }\n  \n  validate() {\n    const missing = this.requiredVars.filter(\n      v => !(v in this.variables)\n    );\n    \n    if (missing.length > 0) {\n      throw new Error(`Variáveis faltando: ${missing.join(', ')}`);\n    }\n    \n    return true;\n  }\n  \n  render() {\n    this.validate();\n    \n    let result = this.template;\n    for (const [key, value] of Object.entries(this.variables)) {\n      result = result.replace(\n        new RegExp(`{${key}}`, 'g'),\n        String(value)\n      );\n    }\n    \n    return result;\n  }\n}\n\n// Uso\nconst codeReviewTemplate = new PromptTemplate(\n  `Você é um {seniority} {language} developer.\n\nRevise o seguinte código:\n\n\\`\\`\\`{language}\n{code}\n\\`\\`\\`\n\nFoque em:\n{reviewPoints}\n\nForneça feedback no formato: {format}`\n);\n\nconst prompt = codeReviewTemplate\n  .setVariable('seniority', 'senior')\n  .setVariable('language', 'JavaScript')\n  .setVariable('code', 'function example() { return null; }')\n  .setVariable('reviewPoints', '- Qualidade\\n- Performance\\n- Segurança')\n  .setVariable('format', 'JSON')\n  .render();\n```\n\n### Templates com Condicionais\n\nTemplates podem incluir lógica condicional:\n\n```javascript\nclass ConditionalTemplate extends PromptTemplate {\n  render() {\n    this.validate();\n    \n    let result = this.template;\n    \n    // Processar condicionais {if:condition}...{/if}\n    result = result.replace(\n      /{if:([^}]+)}([^{]*)\\{\\/if\\}/g,\n      (match, condition, content) => {\n        const conditionValue = this.evaluateCondition(condition);\n        return conditionValue ? content : '';\n      }\n    );\n    \n    // Processar variáveis normais\n    for (const [key, value] of Object.entries(this.variables)) {\n      result = result.replace(\n        new RegExp(`{${key}}`, 'g'),\n        String(value)\n      );\n    }\n    \n    return result;\n  }\n  \n  evaluateCondition(condition) {\n    // Lógica simples de avaliação\n    const [varName, operator, value] = condition.split(' ');\n    const varValue = this.variables[varName];\n    \n    switch (operator) {\n      case '==': return varValue == value;\n      case '!=': return varValue != value;\n      case '>': return varValue > value;\n      case '<': return varValue < value;\n      default: return false;\n    }\n  }\n}\n```\n\n### Biblioteca de Templates\n\nCrie uma biblioteca centralizada de templates:\n\n```javascript\nconst promptTemplates = {\n  codeReview: {\n    template: `...`,\n    defaultVars: { format: 'markdown' }\n  },\n  \n  documentAnalysis: {\n    template: `...`,\n    defaultVars: { depth: 'detailed' }\n  },\n  \n  translation: {\n    template: `...`,\n    defaultVars: { tone: 'formal' }\n  }\n};\n\nfunction getTemplate(name, overrides = {}) {\n  const template = promptTemplates[name];\n  if (!template) {\n    throw new Error(`Template ${name} não encontrado`);\n  }\n  \n  return new PromptTemplate(\n    template.template,\n    { ...template.defaultVars, ...overrides }\n  );\n}\n```\n\n## Redução de Alucinações e Melhoria da Precisão\n\n### O que são Alucinações?\n\nAlucinações em LLMs ocorrem quando o modelo gera informações que parecem plausíveis mas são incorretas, inventadas ou não baseadas nos dados fornecidos. Isso é um dos maiores desafios ao usar LLMs em produção.\n\n### Estratégias para Reduzir Alucinações\n\n#### 1. Fornecer Contexto Específico\n\nQuanto mais contexto específico você fornecer, menor a chance de alucinação:\n\n```javascript\n// ❌ Ruim: Contexto vago\nconst badPrompt = `Explique como funciona a autenticação.`;\n\n// ✅ Bom: Contexto específico\nconst goodPrompt = `Com base na documentação da API abaixo, explique como funciona a autenticação OAuth 2.0 neste sistema específico:\n\n[Documentação da API]\n\nUse apenas informações da documentação fornecida. Se algo não estiver na documentação, indique que a informação não está disponível.`;\n```\n\n#### 2. Solicitar Citações e Fontes\n\nPeça ao modelo para citar fontes e indicar quando não tem certeza:\n\n```javascript\nconst citationPrompt = `Analise o seguinte documento e responda as perguntas.\n\nIMPORTANTE:\n- Cite trechos específicos do documento para cada resposta\n- Se a informação não estiver no documento, diga \"Informação não encontrada no documento\"\n- Indique seu nível de confiança (alto, médio, baixo) para cada resposta\n\nDocumento:\n{document}\n\nPerguntas:\n{questions}`;\n```\n\n#### 3. Usar Few-Shot Learning\n\nForneça exemplos de respostas corretas:\n\n```javascript\nconst fewShotPrompt = `Você é um assistente que responde perguntas sobre produtos. Use APENAS informações do catálogo fornecido.\n\nExemplo 1:\nPergunta: Qual o preço do produto X?\nCatálogo: Produto X - R$ 100\nResposta: O produto X custa R$ 100 (fonte: catálogo)\n\nExemplo 2:\nPergunta: O produto Y tem garantia?\nCatálogo: [não menciona produto Y]\nResposta: Informação não encontrada no catálogo sobre o produto Y.\n\nAgora responda:\nPergunta: {question}\nCatálogo: {catalog}`;\n```\n\n#### 4. Implementar Validação em Múltiplas Etapas\n\nValide respostas em múltiplas etapas:\n\n```javascript\nasync function validatedResponse(prompt, context) {\n  // Etapa 1: Gerar resposta inicial\n  const initialResponse = await generateResponse(prompt, context);\n  \n  // Etapa 2: Verificar se a resposta está baseada no contexto\n  const validation = await validateAgainstContext(\n    initialResponse,\n    context\n  );\n  \n  if (!validation.isValid) {\n    // Etapa 3: Gerar resposta corrigida\n    const correctedPrompt = `A resposta anterior pode conter informações incorretas. \n    Por favor, revise e forneça uma resposta baseada APENAS no seguinte contexto:\n    \n    ${context}\n    \n    Resposta anterior (para referência, não copie se estiver incorreta):\n    ${initialResponse}`;\n    \n    return await generateResponse(correctedPrompt, context);\n  }\n  \n  return initialResponse;\n}\n```\n\n#### 5. Usar Temperature Baixa para Fatos\n\nPara informações factuais, use temperature baixa:\n\n```javascript\n// Para fatos e informações precisas\nconst factualPrompt = {\n  model: 'gpt-4',\n  messages: [...],\n  temperature: 0.1, // Muito baixo para reduzir criatividade\n  top_p: 0.9\n};\n\n// Para criatividade e geração de ideias\nconst creativePrompt = {\n  model: 'gpt-4',\n  messages: [...],\n  temperature: 0.8, // Mais alto para mais criatividade\n  top_p: 0.95\n};\n```\n\n#### 6. Implementar Verificação de Fatos\n\nCrie um sistema de verificação de fatos:\n\n```javascript\nasync function factCheckResponse(response, sourceContext) {\n  const factCheckPrompt = `Você é um verificador de fatos.\n\nVerifique se as seguintes afirmações estão corretas baseadas no contexto fornecido:\n\nAfirmações a verificar:\n${extractClaims(response)}\n\nContexto de referência:\n${sourceContext}\n\nPara cada afirmação, responda:\n- VERDADEIRO: Se está no contexto\n- FALSO: Se contradiz o contexto\n- INCERTO: Se não há informação suficiente\n\nFormato: JSON com array de {claim, status, evidence}`;\n  \n  const verification = await generateResponse(factCheckPrompt);\n  return JSON.parse(verification);\n}\n```\n\n#### 7. Usar RAG (Retrieval-Augmented Generation)\n\nCombine busca de informações com geração:\n\n```javascript\nasync function ragResponse(question) {\n  // 1. Buscar informações relevantes\n  const relevantDocs = await searchKnowledgeBase(question);\n  \n  // 2. Construir contexto\n  const context = relevantDocs\n    .map(doc => `[Fonte: ${doc.source}]\\n${doc.content}`)\n    .join('\\n\\n');\n  \n  // 3. Gerar resposta baseada no contexto\n  const prompt = `Responda a pergunta usando APENAS as informações fornecidas abaixo.\n  Se a resposta não estiver nas informações, diga \"Não tenho informações suficientes\".\n  \n  Informações:\n  ${context}\n  \n  Pergunta: ${question}\n  \n  Resposta:`;\n  \n  return await generateResponse(prompt);\n}\n```\n\n### Técnicas Avançadas de Validação\n\n#### Self-Consistency Check\n\nGere múltiplas respostas e verifique consistência:\n\n```javascript\nasync function selfConsistentResponse(prompt, n = 3) {\n  const responses = await Promise.all(\n    Array(n).fill(null).map(() => generateResponse(prompt))\n  );\n  \n  // Verificar se as respostas são consistentes\n  const consistency = checkConsistency(responses);\n  \n  if (consistency.score > 0.8) {\n    return consistency.mostCommon;\n  } else {\n    // Respostas inconsistentes - requer revisão\n    throw new Error('Respostas inconsistentes detectadas');\n  }\n}\n```\n\n#### Confidence Scoring\n\nPeça ao modelo para indicar confiança:\n\n```javascript\nconst confidencePrompt = `Responda a pergunta e indique seu nível de confiança.\n\nPergunta: {question}\nContexto: {context}\n\nFormato da resposta:\n{\n  \"answer\": \"sua resposta\",\n  \"confidence\": \"alto|médio|baixo\",\n  \"reasoning\": \"por que você tem essa confiança\",\n  \"sources\": [\"fontes usadas\"]\n}`;\n```\n\n## Exemplos Práticos Completos\n\n### Exemplo 1: Sistema de Análise de Código com Validação\n\n```javascript\nclass CodeAnalysisSystem {\n  constructor(openai) {\n    this.openai = openai;\n    this.templates = this.initializeTemplates();\n  }\n  \n  initializeTemplates() {\n    return {\n      analysis: new PromptTemplate(\n        `Analise o seguinte código {language}:\n\n\\`\\`\\`{language}\n{code}\n\\`\\`\\`\n\nForneça:\n1. Análise de qualidade\n2. Possíveis bugs\n3. Sugestões de melhoria\n\nBase sua análise APENAS em práticas conhecidas de {language}.`\n      ),\n      \n      validation: new PromptTemplate(\n        `Verifique se a seguinte análise de código está correta:\n\nCódigo original:\n{code}\n\nAnálise:\n{analysis}\n\nResponda: A análise está correta? (sim/não) e explique.`\n      )\n    };\n  }\n  \n  async analyzeCode(code, language) {\n    // Gerar análise\n    const analysisPrompt = this.templates.analysis\n      .setVariable('code', code)\n      .setVariable('language', language)\n      .render();\n    \n    const analysis = await this.openai.chat.completions.create({\n      model: 'gpt-4',\n      messages: [{ role: 'user', content: analysisPrompt }],\n      temperature: 0.3\n    });\n    \n    const analysisText = analysis.choices[0].message.content;\n    \n    // Validar análise\n    const validationPrompt = this.templates.validation\n      .setVariable('code', code)\n      .setVariable('analysis', analysisText)\n      .render();\n    \n    const validation = await this.openai.chat.completions.create({\n      model: 'gpt-4',\n      messages: [{ role: 'user', content: validationPrompt }],\n      temperature: 0.1\n    });\n    \n    return {\n      analysis: analysisText,\n      validation: validation.choices[0].message.content,\n      timestamp: new Date().toISOString()\n    };\n  }\n}\n```\n\n### Exemplo 2: Sistema de Tradução com Verificação\n\n```javascript\nclass TranslationSystem {\n  async translateWithVerification(text, targetLang, sourceLang = 'auto') {\n    // Etapa 1: Tradução inicial\n    const translation = await this.translate(text, targetLang, sourceLang);\n    \n    // Etapa 2: Verificação de qualidade\n    const qualityCheck = await this.checkQuality(text, translation, targetLang);\n    \n    // Etapa 3: Se qualidade baixa, retraduzir com contexto adicional\n    if (qualityCheck.score < 0.7) {\n      const improvedTranslation = await this.improveTranslation(\n        text,\n        translation,\n        targetLang,\n        qualityCheck.issues\n      );\n      return improvedTranslation;\n    }\n    \n    return translation;\n  }\n  \n  async translate(text, targetLang, sourceLang) {\n    const template = new PromptTemplate(\n      `Traduza o seguinte texto de {sourceLang} para {targetLang}.\n      Mantenha o tom, estilo e significado original.\n      \n      Texto:\n      {text}\n      \n      Tradução:`\n    );\n    \n    const prompt = template\n      .setVariable('text', text)\n      .setVariable('sourceLang', sourceLang)\n      .setVariable('targetLang', targetLang)\n      .render();\n    \n    // ... chamada à API\n  }\n}\n```\n\n## Conclusão\n\nAs técnicas avançadas de prompt engineering apresentadas neste tópico - prompt chaining, templates e redução de alucinações - são fundamentais para construir sistemas de IA robustos e confiáveis em produção.\n\n**Principais Takeaways**:\n\n1. **Prompt Chaining** permite resolver tarefas complexas dividindo-as em etapas gerenciáveis\n2. **Templates** garantem consistência e facilitam manutenção\n3. **Redução de alucinações** requer múltiplas estratégias combinadas: contexto específico, validação, verificação de fatos\n4. **Iteração e refinamento** são essenciais - sempre teste e melhore seus prompts\n5. **Monitoramento** contínuo ajuda a identificar e corrigir problemas\n\nNo próximo tópico, exploraremos como otimizar o uso dessas APIs para reduzir custos e melhorar a eficiência, aplicando as técnicas aprendidas aqui de forma econômica.",
  "resources": [
    {
      "type": "link",
      "title": "Prompt Engineering Guide - OpenAI",
      "url": "https://platform.openai.com/docs/guides/prompt-engineering",
      "description": "Guia oficial de prompt engineering da OpenAI"
    },
    {
      "type": "link",
      "title": "Prompt Engineering Techniques - Anthropic",
      "url": "https://docs.anthropic.com/claude/docs/prompt-engineering",
      "description": "Técnicas de prompt engineering específicas para Claude"
    },
    {
      "type": "document",
      "title": "Chain-of-Thought Prompting - Paper",
      "description": "Paper acadêmico sobre prompt chaining e chain-of-thought reasoning"
    },
    {
      "type": "code",
      "title": "LangChain Prompt Templates",
      "url": "https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/",
      "description": "Biblioteca LangChain com exemplos de prompt templates"
    },
    {
      "type": "link",
      "title": "Reducing Hallucinations in LLMs - Research",
      "description": "Pesquisas e técnicas para reduzir alucinações em modelos de linguagem"
    }
  ]
}

